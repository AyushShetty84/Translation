{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"QWemH6XxUFEp"},"source":["###Import all the necessary modules"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61962,"status":"ok","timestamp":1684834527696,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"NUemt0kDLe8w","outputId":"d1ca6046-c817-4f3d-ec2b-7d22c6c7c9aa","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2009,"status":"ok","timestamp":1684834529700,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"uC6QlOfdUEx1","vscode":{"languageId":"python"}},"outputs":[],"source":["from os.path import isfile\n","import tensorflow as tf\n","import numpy as np\n","import pickle\n","import time\n","import re"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21729,"status":"ok","timestamp":1684834556940,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"_XyiKCVz_O49","outputId":"8018572f-8db0-4b8d-831a-e6447fc47c96","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gradio\n","  Downloading gradio-3.32.0-py3-none-any.whl (19.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles (from gradio)\n","  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n","Collecting aiohttp (from gradio)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client>=0.2.4 (from gradio)\n","  Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio)\n","  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.13.0 (from gradio)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Collecting mdit-py-plugins<=0.3.3 (from gradio)\n","  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n","Collecting orjson (from gradio)\n","  Downloading orjson-3.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n","Collecting python-multipart (from gradio)\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n","Collecting semantic-version (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.0 (from gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (2023.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n","Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n","  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n","Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->gradio)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->gradio)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n","Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n","  Downloading httpcore-0.17.1-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n","Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n","  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=5b44ca1b6c86c102607fb0a9758fe431790c152beb534f04df0f567bf3f20e8a\n","  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, multidict, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, aiosignal, httpx, fastapi, aiohttp, gradio-client, gradio\n","Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 fastapi-0.95.2 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.32.0 gradio-client-0.2.5 h11-0.14.0 httpcore-0.17.1 httpx-0.24.1 huggingface-hub-0.14.1 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 multidict-6.0.4 orjson-3.8.12 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 yarl-1.9.2\n"]}],"source":["pip install gradio"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5836,"status":"ok","timestamp":1684834562771,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"WZ8j3vAHLWhe","outputId":"9141beca-9151-44c6-c198-cf2b34223be8","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting Keras-Preprocessing\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.22.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n","Installing collected packages: Keras-Preprocessing\n","Successfully installed Keras-Preprocessing-1.1.2\n"]}],"source":["pip install Keras-Preprocessing"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2963,"status":"ok","timestamp":1684834565728,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"a9-Y7vjdLWhg","outputId":"7c544c4c-beaa-413e-af2a-a0293704d4fd","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-gpu\n","  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n"]}],"source":["pip install tensorflow-gpu"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1684834565729,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"GghDwtd6LWhg","outputId":"9407ad68-dc43-4537-a640-79a4d32fffa0","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n"," PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["tf.config.list_physical_devices()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1684834565730,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"57axflKMLWhh","vscode":{"languageId":"python"}},"outputs":[],"source":["physical_devices = tf.config.list_physical_devices('GPU')\n","tf.config.experimental.set_memory_growth(physical_devices[0], True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UNOFy1fFUuJp"},"source":["###Choose Translate direction"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1684835239653,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"pP2JBLp9Uznq","vscode":{"languageId":"python"}},"outputs":[],"source":["#Set htoe as true for translation from Hindi to Hnglish; \n","#Set htoe as false for English to Hindi translation\n","htoe = True"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"a-4tRIHdUNN8"},"source":["###Load the Tokenizers"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684835239653,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"vSidzxZZOC_o","vscode":{"languageId":"python"}},"outputs":[],"source":["if htoe:\n","    tokenizer_one = pickle.load(open(\"tokenizer_hi\",\"rb\"))\n","    tokenizer_two = pickle.load(open(\"tokenizer_en\",\"rb\"))\n","else:\n","    tokenizer_one = pickle.load(open(\"tokenizer_en\",\"rb\"))\n","    tokenizer_two = pickle.load(open(\"tokenizer_hi\",\"rb\"))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"l0NwdDczUrlk"},"source":["###Create the dataset - **For training purposes only**"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1684835241190,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"z6BcRWYhUtHK","vscode":{"languageId":"python"}},"outputs":[],"source":["# Tweak the dataset params according to your needs\n","\n","MAX_LENGTH = 64 \n","BUFFER_SIZE = 1000\n","BATCH_SIZE = 100"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684835241191,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"N8vodrv6VO9q","outputId":"974f1ad2-f311-49fc-b4af-4ea662b29c51","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset size: 690722\n"]}],"source":["# Read the dataset objects\n","\n","if htoe:\n","    raw_data_one = pickle.load(open(\"raw_data_hi\",\"rb\"))\n","    raw_data_two = pickle.load(open(\"raw_data_en\",\"rb\"))\n","else:\n","    raw_data_one = pickle.load(open(\"raw_data_en\",\"rb\"))\n","    raw_data_two = pickle.load(open(\"raw_data_hi\",\"rb\"))\n","\n","print(\"Dataset size: {}\".format(len(raw_data_one)))"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1684835241192,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"o5JxTae_VPmn","vscode":{"languageId":"python"}},"outputs":[],"source":["# Utility functions for data preprocessing\n","\n","def encode(lang1, lang2):\n","  lang1 = [len(tokenizer_one.word_index)] + tokenizer_one.texts_to_sequences(\n","      [lang1.numpy().decode(\"utf-8\")])[0] + [len(tokenizer_one.word_index)+1]\n","\n","  lang2 = [len(tokenizer_two.word_index)] + tokenizer_two.texts_to_sequences(\n","      [lang2.numpy().decode(\"utf-8\")])[0] + [len(tokenizer_two.word_index)+1]\n","  \n","  return lang1, lang2\n","\n","def tf_encode(lang1, lang2):\n","  result_one, result_two = tf.py_function(\n","      encode, [lang1, lang2], [tf.int64, tf.int64])\n","  result_one.set_shape([None])\n","  result_two.set_shape([None])\n","\n","  return result_one, result_two\n","\n","def filter_max_length(x, y, max_length=MAX_LENGTH):\n","  return tf.logical_and(tf.size(x) <= max_length,\n","                        tf.size(y) <= max_length)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":5010,"status":"ok","timestamp":1684835246197,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"1AMOBaiHVXti","vscode":{"languageId":"python"}},"outputs":[],"source":["# Obtain tf-data object from the dataset\n","\n","train_examples = tf.data.Dataset.from_tensor_slices((raw_data_one, raw_data_two)) \n","\n","train_preprocessed = (\n","    train_examples \n","    .map(tf_encode)\n","    .filter(filter_max_length)\n","    .cache()\n","    .shuffle(BUFFER_SIZE))\n","\n","train_dataset = (train_preprocessed\n","                 .padded_batch(BATCH_SIZE)\n","                 .prefetch(tf.data.experimental.AUTOTUNE))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"t6IkKAYnVUrb"},"source":["###Create the word embedding matrices"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1684835246198,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"E3iTs5X1VaS8","vscode":{"languageId":"python"}},"outputs":[],"source":["# Define the vocab sizes\n","\n","input_vocab_size = len(tokenizer_one.word_index) + 2\n","target_vocab_size = len(tokenizer_two.word_index) + 2"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684835246198,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"BdImo-P8VdNQ","vscode":{"languageId":"python"}},"outputs":[],"source":["# Load the pretrained embeddings\n","\n","words_en, embeddings_en = pickle.load(\n","    open('polyglot-en.pkl', 'rb'), encoding='latin1')\n","words_hi, embeddings_hi = pickle.load(\n","    open('polyglot-hi.pkl', 'rb'), encoding='latin1')"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684835246198,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"L5OqV9X-Vfb7","vscode":{"languageId":"python"}},"outputs":[],"source":["# English embedding matrix\n","\n","embeddings_index_en = {}\n","if htoe:\n","    word_index_en = tokenizer_two.word_index\n","else:\n","    word_index_en = tokenizer_one.word_index\n","\n","for i in range(len(words_en)):\n","    embeddings_index_en[words_en[i].lower()] = embeddings_en[i]\n","\n","if htoe:\n","    embedding_matrix_en = np.zeros((target_vocab_size, 64))\n","else:\n","    embedding_matrix_en = np.zeros((input_vocab_size, 64))\n","\n","for word, i in word_index_en.items():\n","    embedding_vector = embeddings_index_en.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix_en[i] = embedding_vector"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1684835246199,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"VrYgRR3LViqd","vscode":{"languageId":"python"}},"outputs":[],"source":["# Hindi embedding matrix\n","\n","embeddings_index_hi = {}\n","if htoe:\n","    word_index_hi = tokenizer_one.word_index\n","else:\n","    word_index_hi = tokenizer_two.word_index\n","\n","for i in range(len(words_hi)):\n","    embeddings_index_hi[words_hi[i]] = embeddings_hi[i]\n","\n","if htoe:\n","    embedding_matrix_hi = np.zeros((input_vocab_size, 64))\n","else:\n","    embedding_matrix_hi = np.zeros((target_vocab_size, 64))\n","    \n","for word, i in word_index_hi.items():\n","    embedding_vector = embeddings_index_hi.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix_hi[i] = embedding_vector"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684835246199,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"OBApmP9bYiL1","vscode":{"languageId":"python"}},"outputs":[],"source":["if htoe:\n","    embedding_matrix_one = embedding_matrix_hi\n","    embedding_matrix_two = embedding_matrix_en\n","else:\n","    embedding_matrix_one = embedding_matrix_en\n","    embedding_matrix_two = embedding_matrix_hi"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PjKd29iJY52Y"},"source":["###Create the model"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684835246199,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"sn7ARpFxY049","vscode":{"languageId":"python"}},"outputs":[],"source":["# Set the model Hyperparams\n","\n","num_layers = 6\n","d_model = 64\n","dff = 2048\n","num_heads = 32\n","dropout_rate = 0.1"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1684835246200,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"Dlkn6ckKY74t","vscode":{"languageId":"python"}},"outputs":[],"source":["# Utility functions for the model\n","\n","def positional_encoding(max_pos, d_model):\n","    \"\"\" Returns the positional encoding for all positions\n","\n","    Args:\n","        max_pos: (int) size of required positional embeddings equal to \n","        the vocab size\n","        d_model: (int) model size equal to the embedding size\n","    \n","    Returns:\n","        pe: (tensor of type float32, shape = \n","        (1, max_pos, d_model)) positional encodings of type float32\n","    \"\"\"\n","\n","    theta = np.expand_dims(np.arange(max_pos), 1) / (np.power(10000, \n","    (2 * np.expand_dims(np.arange(d_model), 0) // 2) / d_model))\n","  \n","    # sin(i) for all even i\n","    theta[:, 0::2] = np.sin(theta[:, 0::2]) \n","    \n","    # cos(i) for all odd i\n","    theta[:, 1::2] = np.cos(theta[:, 1::2]) \n","    \n","    pe = np.expand_dims(theta, 0)\n","    \n","    return tf.cast(pe, dtype=tf.float32)\n","\n","def create_padding_mask(seq):\n","    \"\"\" Creates a padding mask for the self attention layer in the decoder\n","    \"\"\"\n","\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    \n","    # (batch_size, 1, 1, seq_len)\n","    return seq[:, tf.newaxis, tf.newaxis, :]  \n","\n","def create_look_ahead_mask(size):\n","  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","  \n","  # (seq_len, seq_len)\n","  return mask  \n","\n","def scaled_dot_product_attention(q, k, v, mask):\n","  \"\"\"Calculate the attention weights.\n","  q, k, v must have matching leading dimensions.\n","  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n","  The mask has different shapes depending on its type(padding or look ahead) \n","  but it must be broadcastable for addition.\n","  \n","  Args:\n","    q: query shape == (..., seq_len_q, depth)\n","    k: key shape == (..., seq_len_k, depth)\n","    v: value shape == (..., seq_len_v, depth_v)\n","    mask: Float tensor with shape broadcastable \n","          to (..., seq_len_q, seq_len_k). Defaults to None.\n","    \n","  Returns:\n","    output, attention_weights\n","  \"\"\"\n","\n","  # (..., seq_len_q, seq_len_k)\n","  matmul_qk = tf.matmul(q, k, transpose_b=True)  \n","  \n","  # scale matmul_qk\n","  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","  # add the mask to the scaled tensor.\n","  if mask is not None:\n","    scaled_attention_logits += (mask * -1e9)  \n","\n","  # softmax is normalized on the last axis (seq_len_k) so that the scores\n","  # add up to 1.\n","  # (..., seq_len_q, seq_len_k)\n","  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  \n","\n","  # (..., seq_len_q, depth_v)\n","  output = tf.matmul(attention_weights, v)  \n","\n","  return output, attention_weights\n","\n","def print_out(q, k, v):\n","  temp_out, temp_attn = scaled_dot_product_attention(\n","      q, k, v, None)\n","  print ('Attention weights are:')\n","  print (temp_attn)\n","  print ('Output is:')\n","  print (temp_out)\n","\n","def point_wise_feed_forward_network(d_model, dff):\n","\n","    # (batch_size, seq_len, dff)\n","  return tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),\n","      tf.keras.layers.Dense(d_model)\n","  ])\n","\n","def create_masks(inp, tar):\n","  # Encoder padding mask\n","  enc_padding_mask = create_padding_mask(inp)\n","  \n","  # Used in the 2nd attention block in the decoder.\n","  # This padding mask is used to mask the encoder outputs.\n","  dec_padding_mask = create_padding_mask(inp)\n","  \n","  # Used in the 1st attention block in the decoder.\n","  # It is used to pad and mask future tokens in the input received by \n","  # the decoder.\n","  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","  dec_target_padding_mask = create_padding_mask(tar)\n","  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","  \n","  return enc_padding_mask, combined_mask, dec_padding_mask"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684835246200,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"A-1mW4d_Y-Cu","vscode":{"languageId":"python"}},"outputs":[],"source":["# Define the Model layers\n","\n","# Multihead Attention keras layer\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads):\n","    super(MultiHeadAttention, self).__init__()\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","    \n","    assert d_model % self.num_heads == 0\n","    \n","    self.depth = d_model // self.num_heads\n","    \n","    self.wq = tf.keras.layers.Dense(d_model)\n","    self.wk = tf.keras.layers.Dense(d_model)\n","    self.wv = tf.keras.layers.Dense(d_model)\n","    \n","    self.dense = tf.keras.layers.Dense(d_model)\n","        \n","  def split_heads(self, x, batch_size):\n","    \"\"\"Split the last dimension into (num_heads, depth).\n","    Transpose the result such that the shape is :\n","    (batch_size, num_heads, seq_len, depth)\n","    \"\"\"\n","    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(x, perm=[0, 2, 1, 3])\n","    \n","  def call(self, v, k, q, mask):\n","    batch_size = tf.shape(q)[0]\n","    \n","    # (batch_size, seq_len, d_model)\n","    q = self.wq(q)  \n","    k = self.wk(k)\n","    v = self.wv(v)\n","    \n","    # (batch_size, num_heads, seq_len_q, depth)\n","    q = self.split_heads(q, batch_size)\n","\n","    # (batch_size, num_heads, seq_len_k, depth)  \n","    k = self.split_heads(k, batch_size)\n","\n","    # (batch_size, num_heads, seq_len_v, depth)\n","    v = self.split_heads(v, batch_size)\n","    \n","    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","    scaled_attention, attention_weights = scaled_dot_product_attention(\n","        q, k, v, mask)\n","    \n","    # (batch_size, seq_len_q, num_heads, depth)\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n","\n","    # (batch_size, seq_len_q, d_model)\n","    concat_attention = tf.reshape(scaled_attention, \n","                                  (batch_size, -1, self.d_model))  \n","\n","    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","        \n","    return output, attention_weights\n","\n","# Encoder keras Layer\n","\n","class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(EncoderLayer, self).__init__()\n","\n","    self.mha = MultiHeadAttention(d_model, num_heads)\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, training, mask):\n","\n","    # (batch_size, input_seq_len, d_model)\n","    attn_output, _ = self.mha(x, x, x, mask)  \n","    attn_output = self.dropout1(attn_output, training=training)\n","    \n","    # (batch_size, input_seq_len, d_model)\n","    out1 = self.layernorm1(x + attn_output)  \n","    \n","    # (batch_size, input_seq_len, d_model)\n","    ffn_output = self.ffn(out1)  \n","    ffn_output = self.dropout2(ffn_output, training=training)\n","    \n","    # (batch_size, input_seq_len, d_model)\n","    out2 = self.layernorm2(out1 + ffn_output)  \n","    \n","    return out2\n","\n","class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n","               maximum_position_encoding, rate=0.1):\n","    super(Encoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    \n","    self.embedding = tf.keras.layers.Embedding(\n","        input_vocab_size, \n","        d_model, \n","        weights = [embedding_matrix_one], \n","        trainable = False)\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, \n","                                            self.d_model)\n","    \n","    \n","    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n","                       for _ in range(num_layers)]\n","  \n","    self.dropout = tf.keras.layers.Dropout(rate)\n","        \n","  def call(self, x, training, mask):\n","\n","    seq_len = tf.shape(x)[1]\n","    \n","    # adding embedding and position encoding.\n","    # (batch_size, input_seq_len, d_model)\n","    x = self.embedding(x)  \n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","\n","    x = self.dropout(x, training=training)\n","    \n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x, training, mask)\n","    \n","    # (batch_size, input_seq_len, d_model)\n","    return x  \n","\n","# Decoder keras layer\n","\n","class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(DecoderLayer, self).__init__()\n","\n","    self.mha1 = MultiHeadAttention(d_model, num_heads)\n","    self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n"," \n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self.dropout3 = tf.keras.layers.Dropout(rate)\n","    \n","    \n","  def call(self, x, enc_output, training, \n","           look_ahead_mask, padding_mask):\n","    # enc_output.shape == (batch_size, input_seq_len, d_model)\n","\n","    # (batch_size, target_seq_len, d_model)\n","    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  \n","    attn1 = self.dropout1(attn1, training=training)\n","    out1 = self.layernorm1(attn1 + x)\n","    \n","    # (batch_size, target_seq_len, d_model)\n","    attn2, attn_weights_block2 = self.mha2(\n","        enc_output, enc_output, out1, padding_mask)  \n","    attn2 = self.dropout2(attn2, training=training)\n","    \n","    # (batch_size, target_seq_len, d_model)\n","    out2 = self.layernorm2(attn2 + out1)  \n","    \n","    # (batch_size, target_seq_len, d_model)\n","    ffn_output = self.ffn(out2)  \n","    ffn_output = self.dropout3(ffn_output, training=training)\n","    \n","    # (batch_size, target_seq_len, d_model)\n","    out3 = self.layernorm3(ffn_output + out2)  \n","    \n","    return out3, attn_weights_block1, attn_weights_block2\n","\n","class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n","               maximum_position_encoding, rate=0.1):\n","    super(Decoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    \n","    self.embedding = tf.keras.layers.Embedding(\n","        target_vocab_size, \n","        d_model, \n","        weights = [embedding_matrix_two], \n","        trainable=False)\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","    \n","    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n","                       for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, enc_output, training, \n","           look_ahead_mask, padding_mask):\n","\n","    seq_len = tf.shape(x)[1]\n","    attention_weights = {}\n","    \n","    # (batch_size, target_seq_len, d_model)\n","    x = self.embedding(x) \n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","    \n","    x = self.dropout(x, training=training)\n","\n","    for i in range(self.num_layers):\n","      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n","                                             look_ahead_mask, padding_mask)\n","      \n","      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n","      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n","    \n","    # x.shape == (batch_size, target_seq_len, d_model)\n","    return x, attention_weights"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684835246200,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"XKNtu-PfY_4R","vscode":{"languageId":"python"}},"outputs":[],"source":["# Define the Model\n","\n","class Transformer(tf.keras.Model):\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n","               target_vocab_size, pe_input, pe_target, rate=0.1):\n","    super(Transformer, self).__init__()\n","\n","    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n","                           input_vocab_size, pe_input, rate)\n","\n","    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n","                           target_vocab_size, pe_target, rate)\n","\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","    \n","  def call(self, inp, tar, training, enc_padding_mask, \n","           look_ahead_mask, dec_padding_mask):\n","\n","    # (batch_size, inp_seq_len, d_model)\n","    enc_output = self.encoder(inp, training, enc_padding_mask)  \n","    \n","    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n","    dec_output, attention_weights = self.decoder(\n","        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n","    \n","    # (batch_size, tar_seq_len, target_vocab_size)\n","    final_output = self.final_layer(dec_output)  \n","    \n","    return final_output, attention_weights"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684835246200,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"GWXpDKiJZB5p","vscode":{"languageId":"python"}},"outputs":[],"source":["# Define the Learning Rate\n","\n","# Custom Learning rate scheduler\n","\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","    \n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","    \n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(tf.cast(step, tf.float32))\n","    arg2 = tf.cast(step, tf.float32) * (self.warmup_steps ** -1.5)\n","    \n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","\n","# create the optimizer object with the custom learning rate\n","learning_rate = CustomSchedule(d_model)\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate, \n","    beta_1=0.9, \n","    beta_2=0.98, \n","    epsilon=1e-9)"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1684835246201,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"tAYh1J_hZEqG","vscode":{"languageId":"python"}},"outputs":[],"source":["# Define the loss for the model\n","\n","# Create the required type of loss\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, \n","    reduction='none')\n","\n","# Define how loss is calculated\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","  \n","  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n","\n","# Create the loss and accuracy objects\n","\n","train_loss = tf.keras.metrics.Mean(\n","    name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","    name='train_accuracy')"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7710,"status":"ok","timestamp":1684835253903,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"gGR2w5ALZGlm","outputId":"1e4da79c-06d4-4eb0-b7ca-c580f4b7a220","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /content/drive/MyDrive/BE_Project/Machine-Translation-using-Transformers-master/transformer_etoh.weights.zip\n","  inflating: transformer_etoh.weights.data-00000-of-00002  \n","  inflating: transformer_etoh.weights.data-00001-of-00002  \n","  inflating: transformer_etoh.weights.index  \n","Archive:  /content/drive/MyDrive/BE_Project/Machine-Translation-using-Transformers-master/transformer_htoe.weights.zip\n","  inflating: transformer_htoe.weights.data-00000-of-00002  \n","  inflating: transformer_htoe.weights.data-00001-of-00002  \n","  inflating: transformer_htoe.weights.index  \n"]}],"source":["# Create the model object with the necessary params\n","\n","# Unzip the weights\n","\n","!unzip -o transformer_etoh.weights.zip\n","!unzip -o transformer_htoe.weights.zip\n","\n","transformer = Transformer(num_layers, d_model, num_heads, dff,\n","                          input_vocab_size, target_vocab_size, \n","                          pe_input=input_vocab_size, \n","                          pe_target=target_vocab_size,\n","                          rate=dropout_rate)\n","\n","#Load any pre-trained weights (Comment out if retraining from scratch)\n","\n","if htoe:\n","  transformer.load_weights('transformer_htoe.weights')\n","else:\n","  transformer.load_weights('transformer_etoh.weights')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dk56C0B1j4rI"},"source":["###Train the model - Not needed for predictions only"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3mWqD9CAj2kL","vscode":{"languageId":"python"}},"outputs":[],"source":["# Define training epochs\n","\n","EPOCHS = 12"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xeIvLVWGj8RT","vscode":{"languageId":"python"}},"outputs":[],"source":["# Define the training step function\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","  tar_inp = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  \n","  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","  \n","  with tf.GradientTape() as tape:\n","    predictions, _ = transformer(inp, tar_inp, \n","                                 True, \n","                                 enc_padding_mask, \n","                                 combined_mask, \n","                                 dec_padding_mask)\n","    loss = loss_function(tar_real, predictions)\n","\n","  gradients = tape.gradient(loss, transformer.trainable_variables)    \n","  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","  \n","  train_loss(loss)\n","  train_accuracy(tar_real, predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# Start training the model\n","weights_dir = './weights_dir'\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  \n","  for (batch, (inp, tar)) in enumerate(train_dataset):\n","    train_step(inp, tar)\n","    \n","    if batch % 50 == 0:\n","      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","    \n","  transformer.save_weights(weights_dir +'transformer_{}.weights'.format(epoch + 1))\n","  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                                train_loss.result(), \n","                                                train_accuracy.result()))\n","\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cbZ1h08-kTuL"},"source":["###Predict sentences using the model"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":810},"executionInfo":{"elapsed":1439,"status":"ok","timestamp":1684835455641,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"_WAUMu_XkUFf","outputId":"62566245-b251-4fb3-e059-85e741a45c79","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n","  super().__init__(\n","/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n","  super().__init__(\n","/usr/local/lib/python3.10/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:666: UserWarning: Cannot load huggingface. Caught Exception: The space huggingface does not exist\n","  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"]},{"name":"stdout","output_type":"stream","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"data":{"application/javascript":"(async (port, path, width, height, cache, element) => {\n                        if (!google.colab.kernel.accessAllowed && !cache) {\n                            return;\n                        }\n                        element.appendChild(document.createTextNode(''));\n                        const url = await google.colab.kernel.proxyPort(port, {cache});\n\n                        const external_link = document.createElement('div');\n                        external_link.innerHTML = `\n                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n                                    https://localhost:${port}${path}\n                                </a>\n                            </div>\n                        `;\n                        element.appendChild(external_link);\n\n                        const iframe = document.createElement('iframe');\n                        iframe.src = new URL(path, url).toString();\n                        iframe.height = height;\n                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n                        iframe.width = width;\n                        iframe.style.border = 0;\n                        element.appendChild(iframe);\n                    })(7863, \"/\", \"100%\", 500, false, window.element)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["# Utility functions for prediction\n","import gradio as gr\n","MAX_LENGTH = 64 \n","\n","def preprocess_string(s):\n","    ''' String preprocessing function\n","\n","    Args:\n","        s: The string to be preprocessed\n","    \n","    Returns:\n","        s: The preprocessed String\n","    '''\n","\n","    if htoe:\n","        s = re.sub(r'[a-zA-Z]', '', s) # Removes english chars from hindi text\n","    s = re.sub(r\"[\\(\\[].*?[\\)\\]]\", \"\", s) # Removes text between braces\n","    s = re.sub(r'([!.?।])', r' \\1', s) #Includes space between some characters\n","    s = re.sub(r'\\s+', r' ', s) #Reduces multispace string to a single space\n","    \n","    return s\n","\n","def evaluate(inp_sentence):\n","  start_token = [len(tokenizer_one.word_index)]\n","  end_token = [len(tokenizer_one.word_index) + 1]\n","  \n","  inp_sentence = start_token + tokenizer_one.texts_to_sequences(\n","      [inp_sentence])[0] + end_token\n","  encoder_input = tf.expand_dims(inp_sentence, 0)\n","  \n","  decoder_input = [len(tokenizer_two.word_index)]\n","  output = tf.expand_dims(decoder_input, 0)\n","    \n","  for i in range(64):\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","        encoder_input, output)\n","  \n","    # predictions.shape == (batch_size, seq_len, vocab_size)\n","    predictions, attention_weights = transformer(encoder_input, \n","                                                 output,\n","                                                 False,\n","                                                 enc_padding_mask,\n","                                                 combined_mask,\n","                                                 dec_padding_mask)\n","    \n","    # select the last word from the seq_len dimension\n","    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n","\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","    \n","    # return the result if the predicted_id is equal to the end token\n","    if predicted_id == len(tokenizer_two.word_index)+1:\n","      return tf.squeeze(output, axis=0), attention_weights\n","    \n","    # concatentate the predicted_id to the output which is given to the decoder\n","    # as its input.\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output, axis=0), attention_weights\n","\n","def translate(sentence):\n","    result, attention_weights = evaluate(sentence)\n","    predicted_sentence = tokenizer_two.sequences_to_texts(\n","        [[i.numpy()] for i in result if i < len(tokenizer_two.word_index)])  \n","    return ' '.join(predicted_sentence)\n","\n","# Wrap your function for Gradio interface\n","\n","\n","# Define the Gradio interface\n","if htoe:\n","  def gradio_translate_interface(hin_text):\n","    return translate(hin_text)\n","\n","  iface = gr.Interface(\n","      fn=gradio_translate_interface, \n","      inputs=gr.inputs.Textbox(lines=2, placeholder='Enter Hindi text here...'), \n","      outputs=gr.outputs.Textbox(label='Translation in English'),\n","      title='Hindi to English Translator',\n","      theme='huggingface'  # just one of the available themes\n","  )\n","else :\n","  def gradio_translate_interface(eng_text):\n","    return translate(eng_text)\n","\n","  iface = gr.Interface(\n","      fn=gradio_translate_interface, \n","      inputs=gr.inputs.Textbox(lines=2, placeholder='Enter English text here...'), \n","      outputs=gr.outputs.Textbox(label='Translation in Hindi'),\n","      title='English to Hindi Translator',\n","      theme='huggingface'  # just one of the available themes\n","  )\n","# Launch the interface\n","iface.launch()"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8366,"status":"ok","timestamp":1684834608783,"user":{"displayName":"Ayush Shetty","userId":"14809064147173665665"},"user_tz":-330},"id":"f9h-euuwlTUR","outputId":"0e49c0de-bcb4-4ac3-8a4b-6d32ddbfcf29","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["क्या मैं आप को मदद सकता हूँ ?\n"]}],"source":["#Enter input sentence\n","inp_str = \"Can I help you?\"\n","\n","print(translate(preprocess_string(inp_str)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USijTyS6fpzv","vscode":{"languageId":"python"}},"outputs":[],"source":["from nltk.translate.bleu_score import sentence_bleu\n","import matplotlib.pyplot as plt\n","\n","# Obtain references and hypotheses\n","references = []\n","hypotheses = []\n","\n","# Array to store BLEU scores\n","bleu_scores = []\n","\n","# Loop through the first 100 examples in the validation dataset\n","for i, (source, target) in enumerate(train_dataset.take(8000)):\n","    # Convert source tensor to sentence string\n","    source_sentence = tokenizer_one.sequences_to_texts(source.numpy())[0]\n","    # Translate source sentence\n","    translated_sentence = translate(source_sentence)\n","    # Convert target tensor to sentence string\n","    target_sentence = tokenizer_two.sequences_to_texts(target.numpy())[0]\n","    \n","    # Append references and hypothesis for this example\n","    references.append([target_sentence.split()])\n","    hypotheses.append(translated_sentence.split())\n","    \n","    # Calculate BLEU score for this example and append to array\n","    bleu_score = sentence_bleu(references[-1], hypotheses[-1])\n","    bleu_scores.append(bleu_score)\n","    \n","    # Print progress every 10 examples\n","    if (i + 1) % 1000 == 0:\n","        print(f\"Translated {i+1} examples\")\n","\n","# Plot the array of BLEU scores\n","plt.plot(range(len(bleu_scores)), bleu_scores)\n","plt.xlabel('Sentence')\n","plt.ylabel('BLEU Score')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["bleu_score = corpus_bleu(references, hypotheses)\n","print(f\"BLEU score: {bleu_score}\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
